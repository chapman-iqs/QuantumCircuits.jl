module QuantumCircuits

	using Reexport
	@reexport using QuantumOpticsBase
	using Distributions
	# using Distributed

	#################################
	# Abstract types and type aliases
	abstract type QObj <: Any end

	# Note implementation is light-weight, using mostly type aliases
	# for the features in Base that do all the real work
	const Time = Float64
	const Rate = Float64
	const Efficiency = Float64
	const QOp = AbstractOperator

	δ(i,j) = Int(i == j);

	"""
		sand(a, b)

	Sandwich `b` operator with `a`.

	### Returns:
	  - Operator: a * b * a'
	"""
	sand(a, b) = a * b * a'



	function bayesian(T::Tuple, ρ, H0, J0, Ctups; fn=ρ->ρ, dt=1e-4, r=[], td=0.0, sample=true)
		ts = range(first(T), last(T), step=dt)
		feedback = applicable(H0, ts[1], [1])
		rsize = length(Ctups)

		return feedback ?
				trajectory(meas(dt, H0, J0, Ctups; rdo=r, ts=ts, td=td, sample=sample), ts, ρ, td; fn=fn, rsize=rsize, dt=dt) :
				trajectory(meas(dt, H0, J0, Ctups; rdo=r, ts=ts, sample=sample), ts, ρ; fn=fn, rsize=rsize, dt=dt)

	end


	"""
	    meas(dt, H; mclist=Tuple{Operator,Time,Float64}[],
	                      mflist=Tuple{Function,Time,Float64}[],
	                      clist=Operator[], flist=Function[])

	Return increment function over a time step `dt` for diffusive monitored
	evolution generated by Hamiltonian `H`, a list `mclist` of tuples specifying
	constant measurement operators, and a list `mflist` of tuples specifying
	time-dependent measurement operators. The tuples have the form `(m, τ, η)`,
	where `m` is a (generally non-Hermitian) operator (or time-dependent function)
	that specifies the measurement backaction (see below), `τ` is the timescale
	of the measurement collapse, and `η` is the measurement efficiency (bounded
	between 0 and 1).

	These quantities are related as follows:
	  - Γ = 1/(2τη) : ensemble measurement dephasing rate
	  - Γm = 1/(2τ) : dephasing rate produced by averaging the collected signal
	  - γ = Γ - Γm = (1-η)/(2τη) : residual dephasing rate from signal loss
	  - ``m = m_o - i m_p``
	  - ``m_o = (m + m')/2``  : measured observable (Hermitian part of `m`)
	  - ``m_p = i(m - m')/2`` : phase-backaction generator (anti-Hermitian part of `m`)

	The backaction takes the form of a three-step process:
	  1. Sample `r` from a Gaussian distribution with mean ``⟨m_o⟩`` and variance τ/dt
	  2. Conditionally update the state with a purity-preserving Kraus operator:
	  - ``M_r = (dt/2πτ)^{1/4} e^{ -i m_p r dt/(2τ) - dt(r - m_o)^2/(4τ) }``
	  3. Apply residual Lindblad dephasing evolution, including
	  - `m` with rate ``γ = (1-η)/(2τη)``
	  - the dephasing operators in `clist` and `flist`
	  - natural Hamiltonian evolution `H`

	Uses the "jump no-jump" method to efficiently approximate the residual
	Lindblad dephasing as a composition of Hamiltonian evolution, jumps,
	and no-jump informational backaction. Assumes no time-dependence in `alist`,
	and small dt.  [Physical Review A **92**, 052306 (2015)]

	### Returns:
	  - (t, ρ(t)::Operator) -> (ρ(t+dt)::Operator, rlist::Float64...)

	"""
	function meas(dt::Float64, H0, J0, C; rdo=Array[], ts=[], td=0, sample=true)

		feedback = applicable(H0, ts[1], [1])
		sim = (length(rdo) == 0)

		# Assemble readout generating functions and Kraus operators
		ros = Function[]
		gks = Function[]

		H = length(methods(H0)) > 0 ? H0 : t -> H0 # if H0 is already a function of t, set H = H0; if H0 = const, define h(t) a constant function of t
		# J = map(j -> length(methods(j)) > 0 ? j : t -> j, J0) # same, for each element of J0
		J = []
		for (j, Γ) in J0
			push!(J, length(methods(Γ)) > 0 ? (t -> √Γ(t) * j) : (t -> √Γ * j) ) end

		# C = []
		# for (c, τm, η) in Ctups
		# 	push!(C, length(methods(τm)) > 0 ? (t -> c,τm,η) : (t -> c,t -> τm,η) ) end

		for (m, Γ, η) in C
			if sim && sample
				push!(ros, readout(dt, m, Γ, η)) end
			push!(gks, gausskraus(dt,  m, Γ, η))
		end

		L = lind(dt, H, clist=[], flist=J)


		if feedback

				(t, ρ, rd) -> begin
					rs = sim ? map(ro -> ro(t, ρ), ros) : map(ro -> ro[argmin(abs.(ts .- t))], rdo)
					gs = map(z -> z[2](t, z[1]), zip(rs, gks))
					ρ1 = foldr(sand, gs; init=ρ);
					return td == 0 ? (L(t, ρ1/tr(ρ1), rs), rs) : (L(t, ρ1/tr(ρ1), rd), rs)
				end
		else
		# Increment that samples each readout, applies all Kraus operators
			# then applies Lindblad dephasing (including Hamiltonian evolution)
			(t, ρ) -> begin
				# for each experimental record (corresponding to each observable), get the value closest to t
				# else, for each simulated record, get the value corresponding to (t,ρ)
				# gives an array (?) of readout values for each observable, at time t.
				rs = sim ? map(ro -> ro(t, ρ), ros) : map(ro -> ro[argmin(abs.(ts .- t))], rdo)

				# for each pair in `zip(rs, gks)`, get the gausskraus operator `z[2]` as a function of `(t,z[1])`,
				# where `z[1]` is the readout value at `t`
				gs = map(z -> z[2](t, z[1]), zip(rs, gks))

				# apply each element of gs via `sand` function (sandwich) to ρ
				ρ1 = foldr(sand, gs; init=ρ);
				return (L(t, ρ1/tr(ρ1)), rs)
			end

		end

	end


	# function readout(dt, (c, τm, η))
	# 	(t, ρ) -> let dist(t) = Normal(0, sqrt(τm(t)/dt))
	# 				real(expect(ρ, c(t)) + rand(dist(t))) end
	#
	# end
	function readout(dt::Time, m::Function, Γ::Function, η::Efficiency)
		(t::Time, ρ) -> let mo = (m(t) .+ m(t)')/2;
							τ = 1/(2Γ(t) * η)
							σ = sqrt(τ/dt);
							σ*randn() + real(expect(ρ, mo)) end
	end
	function readout(dt::Time, m::Function, Γ::Rate, η::Efficiency)
		τ = 1/(2Γ * η)
		σ = sqrt(τ/dt)
		(t::Time, ρ) -> let mo = (m(t) .+ m(t)')/2;
							σ*randn() + real(expect(ρ, mo)) end
	end
	function readout(dt::Time, m::QOp, Γ::Function, η::Efficiency)
		mo = (m .+ m')/2
		(t::Time, ρ) -> let τ = 1/(2Γ(t) * η)
							σ = sqrt(τ/dt);
							σ*randn() + real(expect(ρ, mo)) end
	end
	function readout(dt::Time, m::QOp, Γ::Rate, η::Efficiency)
		τ = 1/(2Γ * η)
		mo = (m .+ m')/2
		σ = sqrt(τ/dt)
		(t::Time, ρ) -> σ*randn() + real(expect(ρ, mo))
	end


	#
	# function gausskraus(dt, (c, τm, η))
	# 	v = dt / 2
	#     (t, r) -> let m(t) = c(t) * sqrt(η / (2τm(t)))
	# 						R = r / sqrt(τm(t)/2)
	# 						mo = (m(t) .+ m(t)') / 2
	#                         mo2 = mo^2 / 2
	#                         exp(DenseOperator((conj(R) * m(t) - mo2) * v)) end
	# end

	# handling all cases for types of m, Γ
	"takes as input Γ, ensemble measurement dephasing rate"
	function gausskraus(dt::Time, m::QOp, Γ::Rate, η::Efficiency)
		τ = 1/(2Γ * η)
		mo = (m .+ m') / 2
		mo2 = mo^2 / 2
		v = dt/(2τ)
		(t::Time, r) -> SparseOperator(exp(dense((r*v)*m - v*mo2)))
	end
	function gausskraus(dt::Time, m::Function, Γ::Rate, η::Efficiency)
		τ = 1/(2Γ * η)
		v = dt/(2*τ)
		(t::Time, r) -> let mo = (m(t) .+ m(t)') / 2
							mo2 = mo^2 / 2
							SparseOperator(exp(dense((r*v) * m(t) - v*mo2))) end
	end
	function gausskraus(dt::Time, m::QOp, Γ::Function, η::Efficiency)
		mo = (m .+ m') / 2
		mo2 = mo^2 / 2
		(t::Time, r) -> let τ = 1/(2Γ(t) * η)
							v = dt/(2*τ)
							SparseOperator(exp(dense((r*v)*m - v*mo2))) end
	end
	function gausskraus(dt::Time, m::Function, Γ::Function, η::Efficiency)
		(t::Time, r) -> let mo = (m(t) .+ m(t)') / 2
							mo2 = mo^2 / 2
							τ = 1/(2Γ(t) * η)
							v = dt/(2*τ)
							SparseOperator(exp(dense((r*v) * m(t) - v*mo2))) end
	end


	@inline function trajectory(inc::Function, ts, ρ; fn::Function=ρ->ρ, rsize=1, dt=1e-4)

		# init
	    ρ0 = ρ
	    r0 = [0.0 for i in 1:rsize]
	    ρs = [fn(ρ0)]
	    recs = [r0]

		for t in ts[2:end]
			 ρ, rs = inc(t, ρ)
			 push!(ρs, fn(ρ))
			 push!(recs, rs)
	 	end

	    recs = collect(eachrow(hcat(recs...)))

	    return solution(ts, ρs, recs)
	end

	@inline function trajectory(inc::Function, ts, ρ, td; fn::Function=ρ->ρ, rsize=1, dt=1e-4)

		# init
		ρ0 = ρ
		r0 = [0.0 for i in 1:rsize]
		ρs = [fn(ρ0)]
		recs = [[] for i in 1:rsize]
		for (i, r) in enumerate(r0)
			push!(recs[i], r) end

		# find time-delay in terms of indices
		td_index = argmin(abs.(ts .- td))

		# before feedback delay is turned on
		for t in ts[2:td_index]
			rd = r0
			ρ, rs = inc(t, ρ, rd)
			push!(ρs, fn(ρ))
			for (i, r) in enumerate(rs)
				push!(recs[i], r) end
		end

		# after feedback buffer is filled
		for i in (td_index + 1):length(ts)
			t = ts[i]
			# rd uses r0 as placeholder if no time delay, since current readout will come from inc
			rd = (td_index == 1) ? r0 : [r[i - (td_index - 1)] for r in recs]
	        ρ, rs = inc(t, ρ, rd)
	        push!(ρs, fn(ρ))
			for (i, r) in enumerate(rs)
				push!(recs[i], r) end
	    end


		return solution(ts, ρs, recs)

	end




	# Jump-nojump Lindblad propagator
	"""
	    lind(dt[, H]; clist=QOp[], flist=Function[])

	Return increment function over a time step `dt` for Lindblad dissipative
	evolution generated by (an optional) Hamiltonian `H` (operator or function),
	a list `clist` of constant dissipative operators, and a list `flist` of
	time-dependent functions returning dissipative operators.

	Uses the "jump no-jump" method to efficiently approximate the exact
	Lindblad propagator as a composition of Hamiltonian evolution, jumps,
	and no-jump informational backaction. Assumes small dt.
	[Physical Review A **92**, 052306 (2015)]

	### Returns:
	  - (t, ρ(t)::Operator) -> ρ(t+dt)
	"""
	function lind(dt; clist=QOp[], flist=Function[])
	    ns = Function[]
	    ds = Function[]
	    # Construct operations for constant operators
	    if isempty(clist)
	        push!(ns, (t, ρ) -> ρ)
	    else
	        Id = identityoperator(first(clist).basis_l)
	        op = DenseOperator(Id - dt * mapreduce(a -> a' * a, +, clist))
	        n::Operator = SparseOperator(op.basis_l, op.basis_r, sqrt(op.data))
	        push!(ns, (t, ρ) -> n * ρ * n)
	        push!(ds, (t, ρ) -> mapreduce(a -> a * ρ * a', +, clist) * dt)
	    end
	    # Construct operations for time-dependent operators
	    if isempty(flist)
	        push!(ns, (t, ρ) -> ρ)
	    else
	        function nf(t)
	            Id = identityoperator(first(flist)(t).basis_l)
	            op = DenseOperator(Id - dt * mapreduce(a -> a(t)' * a(t), +, flist))
	            return SparseOperator(op.basis_l, op.basis_r, sqrt(op.data))
	        end
	        push!(ns, (t, ρ) -> nf(t) * ρ * nf(t))
	        push!(ds, (t, ρ) -> mapreduce(a -> a(t) * ρ * a(t)', +, flist) * dt)
	    end
	    push!(ds, (t, ρ) -> last(ns)(t, first(ns)(t, ρ)))
	    (t, ρ) -> mapreduce(f -> f(t, ρ), +, ds)
	end
	function lind(dt, H; clist=QOp[], flist=Function[])

		feedback = applicable(H, 1, [1])
	    # Rely on Hamiltonian to specify type of H
	    h = ham(dt, H)
	    # Apply Hamiltonian first, then the Lindblad increment
		return feedback ?
				(t, ρ, r) -> lind(dt, clist=clist, flist=flist)(t, h(t, ρ, r)) :
				(t, ρ) -> lind(dt, clist=clist, flist=flist)(t, h(t, ρ))
	end


	# Hamiltonian propagation
	"""
	    ham(dt, H::Operator; ket=false)

	Return increment function for Hamiltonian evolution generated
	by `H` over a time step `dt`.

	Uses an exact (dense) matrix exponential, assuming no time-dependence.

	### Returns:
	  - ket=true  : (t, ψ::QKet) -> u * ψ
	  - ket=false : (t, ρ::Operator)  -> u * ρ * u'

	"""
	function ham(dt, H::Operator)

	    u::Operator = exp( -im * dt * DenseOperator(H))
	    ut = u'
	    (t, ρ::Operator) -> u * ρ * ut

	end
	function ham(dt, H::Function)
		feedback = applicable(H, 1, [1])
		return feedback ?
				(t, state, r) -> ham(dt, H(t, r))(t, state) :
				(t, state) -> ham(dt, H(t))(t, state)
	end
	"""
	    rouchon(T, ρ0, H, J, C; <keyword arguments>)

	Arguments:

	T :: tuple (ti,tf)
	ρ0 :: initial density matrix
	H :: (time-dependent) Hamiltonian
	J :: array of tuples (j, Γ) representing decoherence channel j at rate Γ
	C :: array of tuples (c, τ, η) representing measurement of c with timescale τ and collection efficiency η

	Keyword Arguments:

	dt :: time step; default dt=1e-4
	r :: record; default r=[], i.e. simulation generates record by randomly sampling distribution.
	            record should be input in the shape [r_1,...,r_Nc] given
	            length(C)=Nc collapse operators. Records should have shape
	            r_m[i] indexing the mth trajectory at time ts[i], where
				ts = range(first(T), last(T), step=dt)
	fn : ρ → Any :: eval function (e.g. to return expectation values instead of density matrices)

	Returns: (ts, ρs, r)

	ts :: list of simulation times
	ρs :: fn(ρ) at each simulation time
	r :: input OR simulated record, depending on value of keyword argument r
	"""

	function rouchon(T, ρ, H0, J0, Ctups; fn=ρ->ρ, dt=1e-4, r=[])
	    ts = range(first(T), last(T), step=dt)
	    Id = identityoperator(ρ.basis_l)
	    Nt = length(ts)
	    Nj = length(J0)
	    Nc = length(Ctups)

	    ρs = Any[]

	    H = length(methods(H0)) > 0 ? H0 : t -> H0
	    # J = map(j -> length(methods(j)) > 0 ? j : t -> j, J0)
		J = []
		for (j, Γ) in J0
			push!(J, length(methods(j)) > 0 ? √Γ * j : (t -> √Γ * j) ) end
		C = []
		for (i, (c, τm, η)) in enumerate(Ctups)
			m = c * sqrt(η / 2τm)
			push!(C, length(methods(m)) > 0 ? m : (t -> m))
			# push!(C, length(methods(c)) > 0 ? (c,τm,η) : (t -> c,τm,η))
		end

		# sample / prepare dy array
		sim = (length(r) == 0)
		dy = []
		dW = []
		dist = Normal(0, √dt)

		for (i, (c, τm, η)) in enumerate(Ctups)
			if sim # randomly sample noise time series for EACH stochastic collapse operator C
				push!(dW, rand(dist, Nt))
				push!(dy, zeros(Nt))
			else
				push!(dy, r[i] .* dt ./ sqrt(τm))	end
		end


	    for (n, t) in enumerate(ts)
	        M = Id - im * H(t) * dt

	        # iterate over deterministic collapse operators J
	        D = 0Id
	        for j in 1:Nj
	            M += -0.5J[j](t)' * J[j](t) * dt
	            D += J[j](t) * ρ * J[j](t)' * dt
	        end

	        # initialize dy value, if simulation
	        if sim
	            for (i, (c, τm, η)) in enumerate(Ctups)
	                dy[i][n] = (real(tr(C[i](t) * ρ + ρ * C[i](t)') * dt) + dW[i][n])
	            end
	        end

	        # iterate over stochastic collapse operators C
	        for c in 1:Nc
	            M += C[c](t) * dy[c][n]
	            # D += -C[c](t)*ρ*C[c](t)'*dt

	            # nested sum
	            for s in 1:Nc
	                M += 0.5C[c](t) * C[s](t) * (dy[c][n] * dy[s][n] - δ(c,s) * dt)
	            end
	        end

	        # update ρ according to Rouchon method
	        ρ = M*ρ*M' + D
	        ρ = ρ / tr(ρ)
	        push!(ρs, fn(ρ))
	    end

		# revert to r (normalized) version of record
		if sim
			for (i, (c, τm, η)) in enumerate(Ctups)
				push!(r, dy[i] .* sqrt(τm) ./ dt)
			end
		end


	    return solution(ts, ρs, recs)
	end


	"""
	    ensemble(solve, T, ρ0, H, J, C; <keyword arguments>)

	solve :: solver function
	T :: tuple (ti,tf)
	ρ0 :: initial density matrix
	H :: time-dependent Hamiltonian
	J :: deterministic collapse operators
	C :: stochastic collapse operators

	Keyword Arguments:

	dt :: time step (default dt=1e-4)
	record :: (default record=[]), i.e. simulation generates record time series.
	            record should be input in the shape [rec_1,...,rec_Nc] given
	            length(C)=Nc collapse operators. Records should have shape
	            rec[m][c,n] indexing the mth trajectory at time T[n]
	N :: number of trajectories (default N=10)
	"""

	function ensemble(solve, T, ρ0, H, J, C; dt=1e-4, record=[], N=10, onstart=x->x, kwargs...)
	    data = map(m -> begin
	        onstart(m)
	        r = length(record) >= m ? record[m] : []
			s = solve(T, ρ0, H, J, C; dt=dt, r=r, kwargs...)
	        return (s.ρ, s.r, s.t)
	    end, 1:N)

	    trajectories = collect(ρs for (ρs, r) in data)
	    record = collect(r for (ρs, r) in data)
	    ts = data[1][3]

	    return (ts, trajectories, record)
	end

	"""
	    coarse_grain(fine; <keyword arguments>)
	Argument: fine :: time-series to be coarse-grained
	Keyword Argument: n :: (default n=2), number of elements over which to smooth input time-series
	Returns: coarse :: smoothed time-series of the same length as fine, but having taken a
						moving-average over n elements
	"""


	function coarse_grain(fine::Array; n=2)
	    coarse = []
		for i in 1:(n-1)
			push!(coarse, mean(fine[1:i])) end

		for i in n:length(fine)
			push!(coarse, mean(fine[i-(n-1):i])) end

	    coarse
	end

	function subselect(a=[]; n=2)
	    a[filter(x -> x%n==0, eachindex(a))]
	end

	struct solution
		t::Vector{Float64}
		ρ
		r
	end

	export δ, rouchon, ensemble, meas, trajectory, bayesian, coarse_grain, subselect

end # module
